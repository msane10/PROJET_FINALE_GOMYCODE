ğŸ§ª ClassBot : Rapport d'Ã‰valuation des Classificateurs BayÃ©siens et Arbres de DÃ©cision
ğŸ“Œ Objectif :
Approfondir lâ€™Ã©valuation de modÃ¨les pour classer automatiquement les requÃªtes clients selon trois catÃ©gories :

assistance

facturation

expÃ©dition

Cette phase met l'accent sur deux familles de classificateurs :

ğŸ“˜ Naive Bayes

ğŸŒ³ Decision Tree

ğŸ“ Ã‰tapes rÃ©alisÃ©es :

Chargement des donnÃ©es clients depuis requetes_clients.txt

Nettoyage textuel avancÃ© : suppression de ponctuation, mise en minuscules, suppression des mots vides (stop words) et stemming (racines des mots)

Vectorisation des messages avec TF-IDF enrichi :

Unigrammes + bigrammes

Suppression des termes trop rares ou trop frÃ©quents (min_df, max_df)

SÃ©paration du jeu de donnÃ©es : 80% entraÃ®nement / 20% test

EntraÃ®nement de deux modÃ¨les : MultinomialNB et DecisionTreeClassifier

Optimisation des hyperparamÃ¨tres de lâ€™arbre de dÃ©cision via GridSearchCV

ğŸ” ModÃ¨les Ã©valuÃ©s :

ğŸ“˜ Naive Bayes

Accuracy : ~0.80

Bonnes performances globales avec faible complexitÃ©

Rapide Ã  entraÃ®ner et prÃ©dire

ğŸŒ³ Decision Tree

Accuracy : ~0.78 (avant optimisation)

ModÃ¨le plus explicable mais sensible au surapprentissage

Performance amÃ©liorÃ©e avec GridSearchCV :

Meilleurs paramÃ¨tres : max_depth=10, min_samples_split=5, criterion='entropy'

Accuracy optimisÃ©e : ~0.82

ğŸ¯ Conclusion :
Les deux modÃ¨les sont adaptÃ©s pour une classification de texte simple, mais :

Naive Bayes reste trÃ¨s efficace avec peu de rÃ©glages

Decision Tree optimisÃ© devient plus compÃ©titif avec un bon rÃ©glage de profondeur et de sÃ©paration

Le modÃ¨le Naive Bayes peut Ãªtre conservÃ© comme base lÃ©gÃ¨re et rapide, tandis que lâ€™arbre optimisÃ© peut Ãªtre utilisÃ© lorsque lâ€™explicabilitÃ© ou la personnalisation du comportement est prioritaire.

