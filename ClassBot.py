# √âtape 1 : Chargement et pr√©traitement des donn√©es

import pandas as pd
import re
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.preprocessing import LabelEncoder

# Charger les donn√©es depuis le fichier texte
with open("requetes_clients.txt", "r", encoding="utf-8") as f:
    lines = f.readlines()

# S√©parer chaque ligne en message et √©tiquette
data = [line.strip().split(" ||| ") for line in lines]
df = pd.DataFrame(data, columns=["message", "categorie"])

# Nettoyage de texte de base
def clean_text(text):
    text = text.lower()
    text = re.sub(r"[^a-z√†√¢√ß√©√®√™√´√Æ√Ø√¥√ª√π√º√ø√±√¶≈ì\s]", "", text)  # supprimer ponctuations
    return text

df["message_clean"] = df["message"].apply(clean_text)

# Encodage des √©tiquettes
label_encoder = LabelEncoder()
df["label"] = label_encoder.fit_transform(df["categorie"])

# Vectorisation TF-IDF
vectorizer = TfidfVectorizer()
X = vectorizer.fit_transform(df["message_clean"])
y = df["label"]

# S√©paration en jeu d'entra√Ænement et de test
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)

# Afiicher
#print(df.head())

from sklearn.naive_bayes import MultinomialNB
from sklearn.svm import LinearSVC
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
import seaborn as sns
import matplotlib.pyplot as plt

# Fonction utilitaire pour entra√Æner et √©valuer un mod√®le
def evaluate_model(model, name):
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)

    acc = accuracy_score(y_test, y_pred)
    print(f"\nüìä R√©sultats - {name}")
    print(f"Accuracy : {acc:.4f}")
    print("Rapport de classification :")
    print(classification_report(y_test, y_pred, target_names=label_encoder.classes_))

    # Affichage de la matrice de confusion
    cm = confusion_matrix(y_test, y_pred)
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
                xticklabels=label_encoder.classes_,
                yticklabels=label_encoder.classes_)
    plt.title(f"Matrice de Confusion - {name}")
    plt.xlabel("Pr√©dit")
    plt.ylabel("R√©el")
    plt.show()
    return acc

# Mod√®les √† tester
models = {
    "Naive Bayes": MultinomialNB(),
    "SVM": LinearSVC(),
    "Random Forest": RandomForestClassifier(random_state=42)
}

# √âvaluation
results = {}
for name, model in models.items():
    acc = evaluate_model(model, name)
    results[name] = acc

# S√©lection du meilleur mod√®le
best_model_name = max(results, key=results.get)
print(f"\nüèÜ Le mod√®le le plus performant est : {best_model_name} avec une accuracy de {results[best_model_name]:.4f}")
