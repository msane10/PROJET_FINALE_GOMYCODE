# === PHASE 1 : Classification de textes ===

import pandas as pd
import re
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.preprocessing import LabelEncoder
from sklearn.naive_bayes import MultinomialNB
from sklearn.svm import LinearSVC
from sklearn.ensemble import RandomForestClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
import seaborn as sns
import matplotlib.pyplot as plt
import nltk
from nltk.corpus import stopwords
from nltk.stem.snowball import FrenchStemmer
from sklearn.model_selection import GridSearchCV

nltk.download('stopwords')
stop_words = list(stopwords.words('french'))
stemmer = FrenchStemmer()

# Nettoyage de texte avanc√©
def clean_text(text):
    """Nettoyage am√©lior√© qui conserve plus d'informations"""
    text = text.lower()
    # Garder certains caract√®res sp√©ciaux utiles
    text = re.sub(r"[^a-z√†√¢√ß√©√®√™√´√Æ√Ø√¥√ª√π√º√ø√±√¶≈ì0-9\s'?-]", "", text)
    tokens = text.split()
    # Remplacer le stemming par une lemmatisation ou le supprimer
    tokens = [word for word in tokens if word not in stop_words]
    return " ".join(tokens)

# Chargement des donn√©es - Version am√©lior√©e avec v√©rification
with open("requetes_clients.txt", "r", encoding="utf-8") as f:
    lines = [line.strip().split(" ||| ") for line in f if line.strip() and line.count(" ||| ") == 1]

df = pd.DataFrame(lines, columns=["message", "categorie"])
df = df.dropna()  # Supprime les lignes vides
df = df.reset_index(drop=True)  # R√©initialise les index

# Cr√©ation de la colonne nettoy√©e - Ajout crucial manquant dans la version originale
df["message_clean"] = df["message"].apply(clean_text)

# Encodage des √©tiquettes
label_encoder = LabelEncoder()
df["label"] = label_encoder.fit_transform(df["categorie"])

# V√©rification des donn√©es
print("=== V√âRIFICATION DES DONN√âES ===")
print("Exemples de messages :")
print(df["message"].head())
print("\nCat√©gories uniques :", label_encoder.classes_)
print("Distribution des cat√©gories :")
print(df['categorie'].value_counts())

# Vectorisation TF-IDF am√©lior√©e
vectorizer = TfidfVectorizer(
    ngram_range=(1, 2),
    max_df=0.95,
    min_df=2,
    stop_words=stop_words
)
X = vectorizer.fit_transform(df["message_clean"])
y = df["label"].values  # Conversion en array numpy

# Split train/test - Version plus robuste
X_train, X_test, y_train, y_test = train_test_split(
    X,
    y,
    test_size=0.2,
    random_state=42,
    stratify=y
)

# Fonction d'√©valuation - Conserv√©e identique
def evaluate_model(model, name):
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)
    acc = accuracy_score(y_test, y_pred)
    print(f"\nüìä R√©sultats - {name}")
    print(f"Accuracy : {acc:.4f}")
    print("Rapport de classification :")

    # Utilisez les classes pr√©sentes dans y_test au lieu de label_encoder.classes_
    present_labels = label_encoder.inverse_transform(sorted(set(y_test)))
    print(classification_report(y_test, y_pred, target_names=present_labels, zero_division=0))

    cm = confusion_matrix(y_test, y_pred)
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
                xticklabels=present_labels,
                yticklabels=present_labels)
    plt.title(f"Matrice de Confusion - {name}")
    plt.xlabel("Pr√©dit")
    plt.ylabel("R√©el")
    plt.show()
    return acc

# === PHASE 2 : Comparaison Naive Bayes vs Decision Tree ===
# Objectif : √©valuer les performances initiales de deux mod√®les simples sur des requ√™tes client
# Mod√®les compar√©s : Naive Bayes (texte) et Arbre de D√©cision (logique explicable)

phase2_models = {
    "Naive Bayes": MultinomialNB(),
    "Decision Tree": DecisionTreeClassifier(random_state=42)
}

phase2_results = {}
for name, model in phase2_models.items():
    acc = evaluate_model(model, name)
    phase2_results[name] = acc

best_model_phase2 = max(phase2_results, key=phase2_results.get)
print(f"\nüèÜ Phase 2 - Meilleur mod√®le : {best_model_phase2} avec une accuracy de {phase2_results[best_model_phase2]:.4f}")

# === PHASE 3 : R√©glage des Hyperparam√®tres ===
# Objectif : am√©liorer les performances des mod√®les Naive Bayes et Arbre de D√©cision
# en testant diff√©rents param√®tres √† l'ade de GridSearchCV (validation crois√©e).

# üîç R√©glage de l'Arbre de D√©cision :
# Test de plusieurs valeurs pour max_depth, min_samples_split et criterion.
# Objectif : limiter le surapprentissage et am√©liorer la g√©n√©ralisation.
param_grid_tree = {
    'max_depth': [5, 10, 20, None],
    'min_samples_split': [2, 5, 10],
    'criterion': ['gini', 'entropy']
}

grid_tree = GridSearchCV(DecisionTreeClassifier(random_state=42), param_grid_tree, cv=5, scoring='accuracy')
grid_tree.fit(X_train, y_train)

print("\nüìà Meilleurs param√®tres trouv√©s pour l'arbre de d√©cision:", grid_tree.best_params_)
best_tree_model = grid_tree.best_estimator_
evaluate_model(best_tree_model, "Decision Tree Optimis√©")

# üîç R√©glage de Naive Bayes :
# Test de diff√©rentes valeurs de alpha (lissage de Laplace) pour mieux g√©rer les z√©ros.
param_grid_nb = {
    'alpha': [0.01, 0.1, 0.5, 1.0],  # Valeurs plus basses
    'fit_prior': [True, False]  # Ajouter ce param√®tre
}

grid_nb = GridSearchCV(MultinomialNB(), param_grid_nb, cv=5, scoring='accuracy')
grid_nb.fit(X_train, y_train)

print("\nüìà Meilleur alpha pour Naive Bayes:", grid_nb.best_params_)
best_nb_model = grid_nb.best_estimator_
evaluate_model(best_nb_model, "Naive Bayes Optimis√©")

# üîö R√©sultat attendu :
# - Une meilleure accuracy pour les deux mod√®les
# - Des param√®tres optimaux identifi√©s automatiquement
# - Une comparaison claire entre mod√®les de base et mod√®les optimis√©s


# === PHASE 4 : Phase de laboratoire / Performance ===
# Objectif : L'objectif de votre pr√©sentation doit √™tre de pr√©senter au public
# le concept de chatbots de traitement du langage naturel (NLP) avec NLTK pour la classification de texte.


import joblib

# Sauvegarde du mod√®le Naive Bayes optimis√© et des objets n√©cessaires
joblib.dump(best_nb_model, "model.pkl")
joblib.dump(vectorizer, "vectorizer.pkl")
joblib.dump(label_encoder, "label_encoder.pkl")

print("‚úÖ Mod√®le, vectorizer et label_encoder sauvegard√©s avec succ√®s.")