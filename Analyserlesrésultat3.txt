ğŸ“Š 1. ModÃ¨le : Decision Tree
ğŸ”§ ModÃ¨le optimisÃ© :
ParamÃ¨tres : criterion='gini', max_depth=10, min_samples_split=2

Accuracy : 66,67%

Forces :

TrÃ¨s bon rappel sur expÃ©dition (1.00)

Bonne prÃ©cision globale sur facturation (1.00)

Faiblesses :

Mauvais rappel pour facturation (0.20) â†’ il classe mal cette catÃ©gorie

Globalement dÃ©sÃ©quilibrÃ© (fortes variations entre classes)

ğŸ“‰ ComparÃ© au modÃ¨le initial (Phase 2) :
Performance stable ou lÃ©gÃ¨rement amÃ©liorÃ©e en prÃ©cision pour certaines classes

Mais recall trÃ¨s faible sur facturation : indique un surapprentissage ou mauvaise sÃ©paration de cette classe

ğŸ“˜ 2. ModÃ¨le : Naive Bayes
ğŸ”§ ModÃ¨le optimisÃ© :
ParamÃ¨tre : alpha = 0.1

Accuracy : 80,00%

Ã‰quilibre gÃ©nÃ©ral :

Bonne prÃ©cision sur toutes les classes

Scores F1 proches entre classes (entre 0.73 et 0.89)

Macro/moyenne pondÃ©rÃ©e proches â†’ bon Ã©quilibre entre les catÃ©gories

ğŸ“ˆ ComparÃ© au modÃ¨le initial (Phase 2) :
Accuracy identique ou lÃ©gÃ¨rement amÃ©liorÃ©e

Meilleure homogÃ©nÃ©itÃ© entre les classes

Plus robuste face aux variations dans le texte

ğŸ§  Analyse comparative finale
ModÃ¨le	Accuracy (Phase 2)	Accuracy (OptimisÃ©)	Analyse globale
ğŸŒ³ Decision Tree	~78%	66,67%	Perte de performance, surapprentissage possible
ğŸ“˜ Naive Bayes	~80%	80,00%	Stable et Ã©quilibrÃ© aprÃ¨s rÃ©glage
âœ… Conclusion
Naive Bayes optimisÃ© reste le meilleur choix : fiable, simple, et performant.

Le Decision Tree bien quâ€™optimisÃ©, nâ€™apporte pas de gains rÃ©els, et montre une faible capacitÃ© Ã  gÃ©nÃ©raliser correctement sur certaines classes (notamment facturation).